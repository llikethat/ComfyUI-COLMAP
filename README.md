# ComfyUI-COLMAP

**Structure-from-Motion camera tracking for ComfyUI**

Extract camera intrinsics, extrinsics, and motion data from video sequences using COLMAP's robust SfM pipeline.

![COLMAP Pipeline](https://colmap.github.io//_images/incremental-sfm.png)

## Features

- ğŸ¯ **Robust Camera Tracking** â€” COLMAP's industry-standard SfM
- ğŸ“Š **Motion Analysis** â€” Detect pan, tilt, roll, dolly, truck, crane, drone movements
- ğŸ”„ **Multiple Coordinate Systems** â€” Blender, Unreal, Unity, Maya, OpenGL, USD, etc.
- ğŸ’¾ **Multiple Export Formats** â€” JSON, CSV, Alembic, FBX, Nuke .chan, OpenCV YAML
- ğŸ¬ **SAM3DBody Integration** â€” Optional scene combining with body mesh tracking
- âš¡ **GPU Acceleration** â€” Optional CUDA support for faster processing

## Installation

### 1. Install the Custom Node

```bash
cd ComfyUI/custom_nodes
git clone https://github.com/llikethat/ComfyUI-COLMAP.git
cd ComfyUI-COLMAP
pip install -r requirements.txt
```

### 2. Install COLMAP

**Option A: pycolmap (Recommended)**
```bash
# CPU version
pip install pycolmap

# GPU/CUDA version (Linux only)
pip install pycolmap-cuda12
```

**Option B: COLMAP CLI**
- Ubuntu: `sudo apt install colmap`
- macOS: `brew install colmap`
- Windows: [Download from GitHub](https://github.com/colmap/colmap/releases)

### 3. Optional: Blender (for Alembic/FBX export)
Install Blender and ensure it's in your PATH:
```bash
# Ubuntu
sudo apt install blender

# macOS
brew install --cask blender
```

## Nodes

### ğŸš€ COLMAP Auto Reconstruct
All-in-one node for simple workflows. Takes images, outputs camera data.

**Inputs:**
- `images` â€” Batch of images (from VHS Load Video, etc.)
- `matcher_type` â€” exhaustive, sequential, or vocab_tree
- `feature_type` â€” sift or sift_gpu
- `max_features` â€” Maximum SIFT features per image (default: 8192)
- `min_matches` â€” Minimum matches for image pairs (default: 15)
- `gpu_mode` â€” auto, cpu_only, force_gpu, or force_offload

**Outputs:**
- `camera_data` â€” Complete camera tracking data (CAMERA_DATA type)
- `status` â€” Processing status message
- `sparse_points_preview` â€” Visualization of sparse point cloud

---

### ğŸ¯ COLMAP Feature Extractor
Extract SIFT features from images.

### ğŸ”— COLMAP Feature Matcher
Match features between image pairs.

### ğŸ—ï¸ COLMAP Sparse Reconstructor
Run incremental SfM reconstruction.

### ğŸ“· COLMAP Camera Extractor
Extract camera data from reconstruction with coordinate system conversion.

### ğŸ“Š COLMAP Motion Analyzer
Analyze camera motion to detect:
- **Pan** â€” Horizontal rotation (left/right)
- **Tilt** â€” Vertical rotation (up/down)
- **Roll** â€” Rotation around view axis
- **Dolly** â€” Forward/backward movement
- **Truck** â€” Left/right movement
- **Crane** â€” Up/down movement
- **Motion Classification** â€” Static, handheld, tripod, drone, tracking, orbit

### ğŸ’¾ COLMAP Camera Exporter
Export camera data to various formats:
- **JSON** â€” Universal format with all data
- **CSV** â€” Spreadsheet-compatible
- **Alembic (.abc)** â€” Camera animation for 3D software
- **FBX** â€” 3D scene with animated camera
- **Nuke .chan** â€” VFX compositing format
- **OpenCV YAML** â€” Computer vision applications
- **COLMAP Text** â€” Native COLMAP format

## Workflows

### Basic Camera Tracking
```
[VHS Load Video] â†’ [COLMAP Auto Reconstruct] â†’ [COLMAP Camera Exporter]
                                             â†˜
                                              [COLMAP Motion Analyzer]
```

### Advanced Pipeline
```
[VHS Load Video] â†’ [COLMAP Feature Extractor] â†’ [COLMAP Feature Matcher] 
                                                          â†“
[COLMAP Camera Exporter] â† [COLMAP Camera Extractor] â† [COLMAP Sparse Reconstructor]
```


## Coordinate Systems

| System | Up | Forward | Handedness | Use Case |
|--------|-----|---------|------------|----------|
| `colmap` | -Y | +Z | Right | COLMAP native |
| `blender` | +Z | +Y | Right | Blender, 3D modeling |
| `opengl` | +Y | -Z | Right | OpenGL, WebGL |
| `opencv` | -Y | +Z | Right | Computer vision |
| `unreal` | +Z | +X | Left | Unreal Engine |
| `unity` | +Y | +Z | Left | Unity |
| `maya` | +Y | +Z | Right | Autodesk Maya |
| `houdini` | +Y | -Z | Right | Houdini |
| `usd` | +Y | -Z | Right | Universal Scene Description |

## Camera Motion Output

The motion analyzer provides per-frame motion data:

```json
{
  "frame_001": {
    "rotation": {
      "pan": 2.3,      // degrees/frame
      "tilt": -0.5,
      "roll": 0.1
    },
    "translation": {
      "dolly": 0.02,   // units/frame
      "truck": 0.01,
      "crane": 0.005
    },
    "motion_type": "handheld",
    "speed": 0.15
  }
}
```

## GPU Memory Management

When using ComfyUI with Stable Diffusion models loaded, GPU memory can be a concern. Use the `gpu_mode` option:

| Mode | Description |
|------|-------------|
| `auto` | Automatically detect and use GPU if available |
| `cpu_only` | Force CPU processing (slower but no VRAM conflict) |
| `force_gpu` | Always use GPU (may fail if VRAM is full) |
| `force_offload` | Unload SD models from VRAM before COLMAP processing |

## Tips for Best Results

1. **Image Quality** â€” Use sharp, well-lit images with minimal motion blur
2. **Overlap** â€” Ensure 60-80% overlap between consecutive frames
3. **Avoid** â€” Pure rotation (no parallax), textureless surfaces, moving objects
4. **Sequential Matcher** â€” Best for video sequences with ordered frames
5. **Exhaustive Matcher** â€” Best for unordered photo collections (slower)

## Masking Dynamic Objects (Important!)

**Problem:** COLMAP assumes a static scene. Moving subjects (people, cars) create features that confuse the solver.

**Solution:** Use the `mask` input to exclude dynamic objects:

```
[Video] â”€â”€â”¬â”€â”€â–º [SAM/Segmentation] â”€â”€â–º [Person Mask]
          â”‚                                 â”‚
          â”‚                                 â–¼
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [COLMAP Auto Reconstruct] â”€â”€â–º Clean camera
                                   (mask input)                    tracking
```

**Mask Options:**
| Parameter | Description |
|-----------|-------------|
| `mask` | MASK input - white areas are excluded |
| `mask_mode` | `exclude_white` (default) or `include_white` |
| `mask_dilation` | Expand mask by N pixels (default: 10) |

**Workflow with SAM3DBody:**
1. Run SAM segmentation to get person mask
2. Feed mask to COLMAP (inverted, so person = white = excluded)
3. COLMAP tracks camera using only background features
4. Apply tracked camera to SAM3DBody mesh sequence

## Troubleshooting

### "No valid models produced"
- Check that images have sufficient texture and overlap
- Try lowering `min_matches` threshold
- Try `exhaustive` matcher instead of `sequential`

### "COLMAP not available"
- Install pycolmap: `pip install pycolmap`
- Or install COLMAP CLI and add to PATH

### Out of GPU memory
- Use `gpu_mode: cpu_only`
- Or use `gpu_mode: force_offload` to free SD model VRAM first

## License

MIT License - See LICENSE file

## Credits

- [COLMAP](https://colmap.github.io/) â€” Johannes L. SchÃ¶nberger
- [pycolmap](https://github.com/colmap/colmap/tree/main/pycolmap) â€” COLMAP Python bindings
